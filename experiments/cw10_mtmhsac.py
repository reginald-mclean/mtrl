from paths import *

from dataclasses import dataclass
from pathlib import Path

import tyro

from mtrl.config.networks import ContinuousActionPolicyConfig, QValueFunctionConfig
from mtrl.config.nn import MultiHeadConfig
from mtrl.config.optim import OptimizerConfig
from mtrl.config.rl import OffPolicyTrainingConfig
from mtrl.envs import MetaworldConfig
from mtrl.experiment import Experiment
from mtrl.rl.algorithms import MTSACConfig



@dataclass(frozen=True)
class Args:
    seed: int = 1
    track: bool = False
    wandb_project: str | None = None
    wandb_entity: str | None = None
    data_dir: Path = Path("./experiment_results")
    resume: bool = False
    exp_name: str = 'c10_sac'

def main() -> None:
    args = tyro.cli(Args)

    experiment = Experiment(
        exp_name=f"{args.exp_name}",
        seed=args.seed,
        data_dir=args.data_dir,
        env=MetaworldConfig(
            env_id="CW10",
            exp_name=f"{args.exp_name}",
            num_eval_episodes=25,
            terminate_on_success=False,
            steps_per_env=int(2_000_000),
        ),
        algorithm=MTSACConfig(
            num_tasks=1, # this controls how many tasks you are interacting with at once
            total_tasks=10, # this controls how many total tasks there ever will be
            gamma=0.99,
            actor_config=ContinuousActionPolicyConfig(
                network_config=MultiHeadConfig(
                    num_tasks=10,
                    depth=3,
                    width=400,
                    #optimizer=OptimizerConfig(max_grad_norm=1.0),
                )
            ),
            critic_config=QValueFunctionConfig(
                network_config=MultiHeadConfig(
                    num_tasks=10,
                    depth=3,
                    width=400,
                    #optimizer=OptimizerConfig(max_grad_norm=1.0),
                )
            ),
            num_critics=2,
        ),
        training_config=OffPolicyTrainingConfig(
            total_steps=int(2e7),
            buffer_size=int(1e6),
            batch_size=128,
            evaluation_frequency=int(1_000_000),
        ),
        checkpoint=False,
        resume=args.resume,
    )

    if args.track:
        assert args.wandb_project is not None and args.wandb_entity is not None
        experiment.enable_wandb(
            project=args.wandb_project,
            entity=args.wandb_entity,
            config=experiment,
            resume="allow",
        )

    experiment.run()


if __name__ == "__main__":
    main()
